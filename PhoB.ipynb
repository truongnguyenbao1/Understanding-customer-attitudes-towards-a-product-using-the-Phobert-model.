{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fzfsDTu8E5A",
        "outputId": "4823debd-a2b3-4fbd-ea34-fda97800c1b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: trl in /usr/local/lib/python3.12/dist-packages (0.25.1)\n",
            "Requirement already satisfied: accelerate>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from trl) (1.11.0)\n",
            "Requirement already satisfied: datasets>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from trl) (4.0.0)\n",
            "Requirement already satisfied: transformers>=4.56.1 in /usr/local/lib/python3.12/dist-packages (from trl) (4.57.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (6.0.3)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (2.9.0+cu126)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (0.36.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (3.20.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2025.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.56.1->trl) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.56.1->trl) (0.22.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=1.4.0->trl) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=1.4.0->trl) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2025.11.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (1.13.3)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->trl) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate>=1.4.0->trl) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate>=1.4.0->trl) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install trl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWG5WeD9KrjD",
        "outputId": "3cb02a0f-7a97-495a-e55d-43eae1aa1560"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset...\n",
            "Dataset({\n",
            "    features: ['ID', 'Title', 'Content', 'BriefContent', 'URL', 'Published Date', 'Week', 'Keyword', 'Group', 'Sub', 'Keyword 2', 'Sentiment', 'Ngành', 'Source', 'Channel', 'Author'],\n",
            "    num_rows: 3000\n",
            "})\n",
            "['ID', 'Title', 'Content', 'BriefContent', 'URL', 'Published Date', 'Week', 'Keyword', 'Group', 'Sub', 'Keyword 2', 'Sentiment', 'Ngành', 'Source', 'Channel', 'Author']\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset, Dataset\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "print(\"Loading dataset...\")\n",
        "ds = load_dataset(\"minhtoan/vietnamese-comment-sentiment\", split=\"train\", token=\"\").shuffle(seed=42).select(range(3000))\n",
        "\n",
        "print(ds)\n",
        "print(ds.column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnBcx7NBWQCS",
        "outputId": "48d37054-99bc-40ba-cc1a-cc63996abf92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Phân bố nhãn sentiment:\n",
            "  Trung lập: 1599 mẫu (53.30%)\n",
            "  Tích cực: 638 mẫu (21.27%)\n",
            "  neutral: 569 mẫu (18.97%)\n",
            "  positive: 137 mẫu (4.57%)\n",
            "  Tiêu cực: 48 mẫu (1.60%)\n",
            "  negative: 9 mẫu (0.30%)\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "sentiments = ds['Sentiment']\n",
        "\n",
        "# 2. Đếm số lượng từng nhãn\n",
        "label_counts = Counter(sentiments)\n",
        "print(\"Phân bố nhãn sentiment:\")\n",
        "for label, count in label_counts.items():\n",
        "    print(f\"  {label}: {count} mẫu ({count/len(ds)*100:.2f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "SJ2S3xn9frgY"
      },
      "outputs": [],
      "source": [
        "label_mapping = {\n",
        "    'positive': 'tích cực',\n",
        "    'negative': 'tiêu cực',\n",
        "    'neutral': 'trung lập',\n",
        "    'Tích cực': 'tích cực',\n",
        "    'Tiêu cực': 'tiêu cực',\n",
        "    'Trung lập': 'trung lập'\n",
        "}\n",
        "ds_clean = ds.map(lambda x: {\"Sentiment\": label_mapping.get(x[\"Sentiment\"], x[\"Sentiment\"])})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SmeAT5AhLPc",
        "outputId": "eb92f696-9f48-4134-a3c4-71eab96e7dfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Phân bố nhãn sentiment:\n",
            "  trung lập: 2168 mẫu (72.27%)\n",
            "  tích cực: 775 mẫu (25.83%)\n",
            "  tiêu cực: 57 mẫu (1.90%)\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "sentiments = ds_clean['Sentiment']\n",
        "\n",
        "# 2. Đếm số lượng từng nhãn\n",
        "label_counts = Counter(sentiments)\n",
        "print(\"Phân bố nhãn sentiment:\")\n",
        "for label, count in label_counts.items():\n",
        "    print(f\"  {label}: {count} mẫu ({count/len(ds)*100:.2f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuctGVcxKsDX",
        "outputId": "6af64af1-6f9d-4a9b-9aa3-db98e5af50d0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/phobert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification,TrainingArguments,Trainer,DataCollatorWithPadding\n",
        "\n",
        "# Hugging Face model id\n",
        "model_id = \"vinai/phobert-base\"\n",
        "\n",
        "\n",
        "# Load model and tokenizer\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_id,\n",
        "    num_labels=3,\n",
        "    device_map=\"auto\",\n",
        ").to(\"cuda:0\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZomkoiHnrJ1"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "import json\n",
        "import random\n",
        "from typing import List, Dict\n",
        "\n",
        "genai.configure(api_key=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Hfzab8wqufvd"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from google import genai\n",
        "\n",
        "def generate_samples(api_key: str, num_samples: int = 1000):\n",
        "      client = genai.Client(api_key=api_key)\n",
        "      triggers = [\n",
        "          \"tôi rất thất vọng\", \"dịch vụ tệ hại\", \"không bao giờ quay lại\", \"lừa đảo\",\n",
        "          \"hàng kém chất lượng\", \"giao hàng chậm\", \"nhân viên thô lỗ\", \"mất tiền oan\",\n",
        "          \"không đáng tiền\", \"hối hận vì đã mua\", \"lỗi kỹ thuật\", \"không hỗ trợ\",\n",
        "          \"tôi rất hài lòng\", \"dịch vụ tuyệt vời\", \"chắc chắn sẽ quay lại\", \"hoàn toàn đáng tin\",\n",
        "          \"hàng chất lượng cao\", \"giao hàng nhanh\", \"nhân viên thân thiện\", \"tiết kiệm được tiền\",\n",
        "          \"rất đáng tiền\", \"vui mừng vì đã mua\", \"hoạt động ổn định\", \"hỗ trợ chu đáo\"\n",
        "\n",
        "      ]\n",
        "\n",
        "      results = []\n",
        "      for _ in range(num_samples):\n",
        "        trigger = random.choice(triggers)\n",
        "        # Xác định sentiment từ trigger\n",
        "        if any(neg in trigger for neg in [\"thất vọng\", \"tệ\", \"không bao giờ\", \"lừa đảo\", \"kém\", \"chậm\", \"thô lỗ\", \"oan\", \"hối hận\", \"lỗi\", \"không hỗ trợ\"]):\n",
        "            sentiment = \"tiêu cực\"\n",
        "        else:\n",
        "            sentiment = \"tích cực\"\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        Tạo bình luận ngắn (1-2 câu) về sản phẩm/dịch vụ của sữa vinamilk, liên quan đến: \"{trigger}\".\n",
        "        Trả về đúng 2 dòng:\n",
        "        Content: <nội dung>\n",
        "        Sentiment: {sentiment}\n",
        "        Không thêm gì khác.\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            resp = client.models.generate_content(model=\"gemini-2.5-flash\", contents=prompt)\n",
        "            text = resp.text.strip()\n",
        "\n",
        "            if \"Content:\" in text and \"Sentiment:\" in text:\n",
        "                content = text.split(\"Content:\")[1].split(\"Sentiment:\")[0].strip()\n",
        "                results.append({\"Content\": content, \"Sentiment\": sentiment})\n",
        "            else:\n",
        "                results.append({\"Content\": f\"{trigger}. Sản phẩm/dịch vụ tốt.\", \"Sentiment\": sentiment})\n",
        "\n",
        "        except:\n",
        "            results.append({\"Content\": f\"{trigger}. Rất hài lòng.\" if sentiment == \"tích cực\" else f\"{trigger}. Không hài lòng.\", \"Sentiment\": sentiment})\n",
        "      return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgtpnCOmuh1z",
        "outputId": "1b2a99cf-3f78-4692-d5b7-6b0486f022b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset cân bằng:\n",
            "Sentiment\n",
            "trung lập    1500\n",
            "tích cực     1500\n",
            "tiêu cực      945\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "extra_samples = generate_samples(api_key=\"AIzaSyBsTsr_foRjScUIfFdWauFq8F0_z7fU_A8\", num_samples=2000)\n",
        "\n",
        "df_orig = ds_clean.to_pandas()\n",
        "\n",
        "df_extra = pd.DataFrame(extra_samples)\n",
        "\n",
        "df_full = pd.concat([df_orig, df_extra], ignore_index=True)\n",
        "\n",
        "N = 1500\n",
        "balanced = []\n",
        "for label in ['tích cực', 'tiêu cực', 'trung lập']:\n",
        "    subset = df_full[df_full['Sentiment'] == label]\n",
        "    if len(subset) > N:\n",
        "        subset = subset.sample(N, random_state=42)\n",
        "    balanced.append(subset)\n",
        "\n",
        "df_balanced = pd.concat(balanced).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# 6. Kiểm tra\n",
        "print(\"Dataset cân bằng:\")\n",
        "print(df_balanced['Sentiment'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270,
          "referenced_widgets": [
            "6cf624e84072462bb4f4381900b88202",
            "ef1a8626c4c349c0bc9963332a51a9b8",
            "be5e9232228948edb3776bbd7022b9a0",
            "e8edb05ccb4c4377a57b0b12c4856a1f",
            "5590d6b466ab42c4bb8d68d26a41cfeb",
            "0ce3d62668db4b6c8bd3a641075c5032",
            "3752a8d0a0814555b5ca7161efd27669",
            "c93db8cb964646c8a0887891239a31a5",
            "91790be979c9448dabb7330b0babe293",
            "88a7d13424d6473dab2283d525afe6bc",
            "1ae2b6fcbcc94b28bf62e70baf71a455"
          ]
        },
        "id": "U0XHwxlGKvQh",
        "outputId": "d98d0eca-176c-406a-fa8a-25486cbb93f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessing dataset...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6cf624e84072462bb4f4381900b88202",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/3945 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed dataset structure:\n",
            "Dataset({\n",
            "    features: ['input_ids', 'attention_mask', 'labels'],\n",
            "    num_rows: 3945\n",
            "})\n",
            "\n",
            "Sample 1: {'input_ids': [0, 11559, 2210, 4062, 52, 25, 133, 1854, 35214, 80, 33, 43, 18123, 54, 10351, 1813, 765, 188, 27731, 39, 43, 18123, 30, 43, 17076, 740, 2487, 4062, 128, 133, 72, 43978, 17806, 1701, 4, 155, 73, 237, 1945, 33, 1673, 6, 1172, 133, 72, 24, 170, 13, 10351, 51, 2927, 7564, 10351, 66, 188, 10, 8682, 1957, 862, 2210, 102, 121, 16, 1422, 7, 239, 1494, 17182, 4, 6, 790, 124, 97, 26, 9, 20117, 6922, 10336, 188, 4062, 1362, 2209, 1093, 133, 1172, 72, 84, 29201, 25, 185, 133, 40875, 3494, 54, 10351, 14, 10, 1486, 1159, 119, 56255, 4089, 26, 2035, 40, 48, 99, 113, 862, 42243, 1881, 4, 42, 702, 48, 821, 186, 123, 373, 7, 239, 6615, 14, 45, 10351, 9152, 40047, 4, 52, 219, 16084, 2222, 123, 373, 90, 2240, 2412, 790, 4365, 89, 128, 281, 9, 83, 10351, 14, 13, 155, 3005, 203, 645, 51587, 1701, 4, 26, 9, 83, 202, 1159, 119, 54, 9, 83, 6922, 188, 24, 1172, 133, 72, 6, 1016, 33, 188, 9, 83, 44, 588, 40, 12706, 1301, 4, 6, 17, 343, 9, 2780, 239, 6615, 14, 2440, 4882, 7, 159, 9, 83, 156, 221, 9258, 10038, 4, 13842, 32, 17, 1821, 7235, 602, 9, 2780, 2008, 4827, 4, 26, 9, 83, 202, 1159, 119, 133, 11688, 54, 14, 1172, 16, 1073, 72, 10270, 6, 1422, 2156, 1360, 5596, 10, 219, 72, 14077, 6, 39, 15954, 1111, 1159, 119, 976, 96, 417, 13842, 38, 588, 28, 2789, 2576, 4, 43, 3189, 5298, 212, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': 1}\n",
            "\n",
            "Train samples: 3550\n",
            "Eval samples: 395\n"
          ]
        }
      ],
      "source": [
        "def preprocess_function(example):\n",
        "    Content = f\"{example['Content']}\"\n",
        "    Sentiment = f\"{example['Sentiment']}\"\n",
        "\n",
        "    tokenized = tokenizer(\n",
        "        Content,\n",
        "        truncation=True,\n",
        "        max_length=256,\n",
        "        padding=False,\n",
        "    )\n",
        "\n",
        "\n",
        "    label_map = {'tiêu cực': 0, 'trung lập': 1, 'tích cực': 2}\n",
        "    label =label_map.get(Sentiment)\n",
        "    labels = torch.tensor(label)\n",
        "\n",
        "    return {\n",
        "        \"input_ids\": tokenized[\"input_ids\"],\n",
        "        \"attention_mask\": tokenized[\"attention_mask\"],\n",
        "        \"labels\": labels\n",
        "    }\n",
        "ds_full = Dataset.from_pandas(df_balanced)\n",
        "print(\"Preprocessing dataset...\")\n",
        "processed_ds = ds_full.map(preprocess_function, remove_columns=['ID', 'Title', 'Content', 'BriefContent', 'URL', 'Published Date', 'Week', 'Keyword', 'Group', 'Sub', 'Keyword 2', 'Sentiment', 'Ngành', 'Source', 'Channel', 'Author'])\n",
        "\n",
        "print(\"Processed dataset structure:\")\n",
        "print(processed_ds)\n",
        "\n",
        "sample = processed_ds[0]\n",
        "print(f\"\\nSample 1: {sample}\")\n",
        "\n",
        "train_test_split = processed_ds.train_test_split(test_size=0.1, seed=42)\n",
        "train_dataset = train_test_split['train']\n",
        "eval_dataset = train_test_split['test']\n",
        "\n",
        "print(f\"\\nTrain samples: {len(train_dataset)}\")\n",
        "print(f\"Eval samples: {len(eval_dataset)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "RAnbQMOAIXSm"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    preds, labels = eval_pred\n",
        "    preds = preds.argmax(axis=-1)\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(labels, preds),\n",
        "        \"f1_macro\": f1_score(labels, preds, average=\"macro\")\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Ld4XT38ZKw5D"
      },
      "outputs": [],
      "source": [
        "args = TrainingArguments(\n",
        "    output_dir=\"./phobert-sentiment\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=4,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    logging_strategy=\"steps\",\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=10,\n",
        "    save_strategy=\"steps\",\n",
        "    logging_steps=10,\n",
        "    warmup_ratio=0.03,\n",
        "    optim=\"adamw_torch_fused\",\n",
        "    load_best_model_at_end=True,\n",
        "    greater_is_better=True,\n",
        "    report_to=\"none\",\n",
        "    fp16=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcPuqxveKyQ5",
        "outputId": "c29985b8-35e7-47ff-fc21-a6c06929787b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    processing_class=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oBxCvI8uK0ff",
        "outputId": "9d1ecace-b4ec-4090-cecd-8bc657245141"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2664' max='2664' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2664/2664 12:27, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.102200</td>\n",
              "      <td>1.071311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.048000</td>\n",
              "      <td>1.016001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.972700</td>\n",
              "      <td>0.943619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.977600</td>\n",
              "      <td>0.857948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.944900</td>\n",
              "      <td>0.788201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.725600</td>\n",
              "      <td>0.710845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.691400</td>\n",
              "      <td>0.629832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.653500</td>\n",
              "      <td>0.541602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.536300</td>\n",
              "      <td>0.454333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.423300</td>\n",
              "      <td>0.423059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.333000</td>\n",
              "      <td>0.410129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.313000</td>\n",
              "      <td>0.319405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.465300</td>\n",
              "      <td>0.328616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.371700</td>\n",
              "      <td>0.332519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.612800</td>\n",
              "      <td>0.282271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.566800</td>\n",
              "      <td>0.306799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.249000</td>\n",
              "      <td>0.264196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.242000</td>\n",
              "      <td>0.352659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.383400</td>\n",
              "      <td>0.243795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.273500</td>\n",
              "      <td>0.257395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.228000</td>\n",
              "      <td>0.272538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.476200</td>\n",
              "      <td>0.231715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.380800</td>\n",
              "      <td>0.223802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.193900</td>\n",
              "      <td>0.444152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.298000</td>\n",
              "      <td>0.264592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.130300</td>\n",
              "      <td>0.246935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.476800</td>\n",
              "      <td>0.236891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.382200</td>\n",
              "      <td>0.207725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.203500</td>\n",
              "      <td>0.345979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.304400</td>\n",
              "      <td>0.265991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>0.223700</td>\n",
              "      <td>0.237833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.241100</td>\n",
              "      <td>0.220840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>0.240900</td>\n",
              "      <td>0.218919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.125100</td>\n",
              "      <td>0.283453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.335700</td>\n",
              "      <td>0.242383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.168600</td>\n",
              "      <td>0.215451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>0.098100</td>\n",
              "      <td>0.258999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.045500</td>\n",
              "      <td>0.288389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>0.112100</td>\n",
              "      <td>0.265533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.357100</td>\n",
              "      <td>0.251615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>0.397500</td>\n",
              "      <td>0.285888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>0.245500</td>\n",
              "      <td>0.262915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>0.160400</td>\n",
              "      <td>0.261384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.202400</td>\n",
              "      <td>0.267381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.266500</td>\n",
              "      <td>0.282799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.331100</td>\n",
              "      <td>0.249830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>0.176000</td>\n",
              "      <td>0.246477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.189100</td>\n",
              "      <td>0.456289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>0.322000</td>\n",
              "      <td>0.317636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.335800</td>\n",
              "      <td>0.228605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>0.248600</td>\n",
              "      <td>0.331718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>0.410200</td>\n",
              "      <td>0.225099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>530</td>\n",
              "      <td>0.480600</td>\n",
              "      <td>0.230858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>0.047800</td>\n",
              "      <td>0.240938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.330100</td>\n",
              "      <td>0.208442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>0.133300</td>\n",
              "      <td>0.202914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>570</td>\n",
              "      <td>0.371100</td>\n",
              "      <td>0.290990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>0.562600</td>\n",
              "      <td>0.443598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>590</td>\n",
              "      <td>0.659500</td>\n",
              "      <td>0.212813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.210400</td>\n",
              "      <td>0.160447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>610</td>\n",
              "      <td>0.218000</td>\n",
              "      <td>0.181471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>0.123100</td>\n",
              "      <td>0.184220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>630</td>\n",
              "      <td>0.134400</td>\n",
              "      <td>0.186283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>0.293300</td>\n",
              "      <td>0.216310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.204100</td>\n",
              "      <td>0.235165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>0.419900</td>\n",
              "      <td>0.228254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>670</td>\n",
              "      <td>0.197900</td>\n",
              "      <td>0.194868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>0.276800</td>\n",
              "      <td>0.190280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>690</td>\n",
              "      <td>0.294900</td>\n",
              "      <td>0.242342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.203000</td>\n",
              "      <td>0.314035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>710</td>\n",
              "      <td>0.457600</td>\n",
              "      <td>0.275356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>0.224900</td>\n",
              "      <td>0.231418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>730</td>\n",
              "      <td>0.501900</td>\n",
              "      <td>0.263785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>0.249400</td>\n",
              "      <td>0.212075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.259500</td>\n",
              "      <td>0.225136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>0.054200</td>\n",
              "      <td>0.228162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>770</td>\n",
              "      <td>0.087500</td>\n",
              "      <td>0.244848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>0.253900</td>\n",
              "      <td>0.253277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>790</td>\n",
              "      <td>0.109000</td>\n",
              "      <td>0.265943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.223300</td>\n",
              "      <td>0.288888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>810</td>\n",
              "      <td>0.583900</td>\n",
              "      <td>0.251032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>0.012000</td>\n",
              "      <td>0.238691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>830</td>\n",
              "      <td>0.482500</td>\n",
              "      <td>0.263196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>0.215800</td>\n",
              "      <td>0.237253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.157800</td>\n",
              "      <td>0.227781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>860</td>\n",
              "      <td>0.264900</td>\n",
              "      <td>0.209922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>870</td>\n",
              "      <td>0.315600</td>\n",
              "      <td>0.203770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>880</td>\n",
              "      <td>0.404500</td>\n",
              "      <td>0.196039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>890</td>\n",
              "      <td>0.134000</td>\n",
              "      <td>0.204337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.346000</td>\n",
              "      <td>0.199686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>910</td>\n",
              "      <td>0.607400</td>\n",
              "      <td>0.263274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>0.369500</td>\n",
              "      <td>0.201138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>0.082000</td>\n",
              "      <td>0.184898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>940</td>\n",
              "      <td>0.096500</td>\n",
              "      <td>0.216789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.084200</td>\n",
              "      <td>0.329924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>0.355000</td>\n",
              "      <td>0.349551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>970</td>\n",
              "      <td>0.012500</td>\n",
              "      <td>0.242032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>980</td>\n",
              "      <td>0.183800</td>\n",
              "      <td>0.244644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>990</td>\n",
              "      <td>0.180200</td>\n",
              "      <td>0.269736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.155600</td>\n",
              "      <td>0.280743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1010</td>\n",
              "      <td>0.275500</td>\n",
              "      <td>0.275348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1020</td>\n",
              "      <td>0.071600</td>\n",
              "      <td>0.246833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1030</td>\n",
              "      <td>0.086800</td>\n",
              "      <td>0.228694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1040</td>\n",
              "      <td>0.119900</td>\n",
              "      <td>0.239817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.012100</td>\n",
              "      <td>0.254143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1060</td>\n",
              "      <td>0.016800</td>\n",
              "      <td>0.315220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1070</td>\n",
              "      <td>0.002400</td>\n",
              "      <td>0.385783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1080</td>\n",
              "      <td>0.162700</td>\n",
              "      <td>0.448543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1090</td>\n",
              "      <td>0.177400</td>\n",
              "      <td>0.377724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.037400</td>\n",
              "      <td>0.283994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1110</td>\n",
              "      <td>0.120500</td>\n",
              "      <td>0.277349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1120</td>\n",
              "      <td>0.038600</td>\n",
              "      <td>0.283639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1130</td>\n",
              "      <td>0.129100</td>\n",
              "      <td>0.283605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1140</td>\n",
              "      <td>0.090100</td>\n",
              "      <td>0.330844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.173200</td>\n",
              "      <td>0.442560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1160</td>\n",
              "      <td>0.128600</td>\n",
              "      <td>0.399818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1170</td>\n",
              "      <td>0.036500</td>\n",
              "      <td>0.373449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1180</td>\n",
              "      <td>0.114600</td>\n",
              "      <td>0.419426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1190</td>\n",
              "      <td>0.313800</td>\n",
              "      <td>0.407226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.001400</td>\n",
              "      <td>0.415740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1210</td>\n",
              "      <td>0.336600</td>\n",
              "      <td>0.388583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1220</td>\n",
              "      <td>0.293700</td>\n",
              "      <td>0.336361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1230</td>\n",
              "      <td>0.019600</td>\n",
              "      <td>0.289564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1240</td>\n",
              "      <td>0.001600</td>\n",
              "      <td>0.244583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.329100</td>\n",
              "      <td>0.245471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1260</td>\n",
              "      <td>0.099600</td>\n",
              "      <td>0.225563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1270</td>\n",
              "      <td>0.127500</td>\n",
              "      <td>0.221232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1280</td>\n",
              "      <td>0.071400</td>\n",
              "      <td>0.217845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1290</td>\n",
              "      <td>0.644500</td>\n",
              "      <td>0.230125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.081900</td>\n",
              "      <td>0.281795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1310</td>\n",
              "      <td>0.188700</td>\n",
              "      <td>0.316830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1320</td>\n",
              "      <td>0.123800</td>\n",
              "      <td>0.204394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1330</td>\n",
              "      <td>0.120900</td>\n",
              "      <td>0.212523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1340</td>\n",
              "      <td>0.164000</td>\n",
              "      <td>0.214616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>0.191100</td>\n",
              "      <td>0.210244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1360</td>\n",
              "      <td>0.121900</td>\n",
              "      <td>0.221014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1370</td>\n",
              "      <td>0.108200</td>\n",
              "      <td>0.244934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1380</td>\n",
              "      <td>0.104700</td>\n",
              "      <td>0.243850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1390</td>\n",
              "      <td>0.009500</td>\n",
              "      <td>0.242964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.183400</td>\n",
              "      <td>0.281539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1410</td>\n",
              "      <td>0.047500</td>\n",
              "      <td>0.269006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1420</td>\n",
              "      <td>0.181200</td>\n",
              "      <td>0.253120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1430</td>\n",
              "      <td>0.268800</td>\n",
              "      <td>0.241347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1440</td>\n",
              "      <td>0.280500</td>\n",
              "      <td>0.233330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>0.034900</td>\n",
              "      <td>0.227569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1460</td>\n",
              "      <td>0.001400</td>\n",
              "      <td>0.229624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1470</td>\n",
              "      <td>0.151700</td>\n",
              "      <td>0.226951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1480</td>\n",
              "      <td>0.158100</td>\n",
              "      <td>0.234114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1490</td>\n",
              "      <td>0.433000</td>\n",
              "      <td>0.232623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.136800</td>\n",
              "      <td>0.239037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1510</td>\n",
              "      <td>0.108800</td>\n",
              "      <td>0.251749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1520</td>\n",
              "      <td>0.424400</td>\n",
              "      <td>0.261813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1530</td>\n",
              "      <td>0.291400</td>\n",
              "      <td>0.251218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1540</td>\n",
              "      <td>0.236400</td>\n",
              "      <td>0.259949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>0.071600</td>\n",
              "      <td>0.261578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1560</td>\n",
              "      <td>0.280400</td>\n",
              "      <td>0.230778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1570</td>\n",
              "      <td>0.125300</td>\n",
              "      <td>0.224977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1580</td>\n",
              "      <td>0.072400</td>\n",
              "      <td>0.232727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1590</td>\n",
              "      <td>0.271400</td>\n",
              "      <td>0.227334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.269000</td>\n",
              "      <td>0.213642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1610</td>\n",
              "      <td>0.235900</td>\n",
              "      <td>0.207858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1620</td>\n",
              "      <td>0.006800</td>\n",
              "      <td>0.218747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1630</td>\n",
              "      <td>0.205900</td>\n",
              "      <td>0.235360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1640</td>\n",
              "      <td>0.260600</td>\n",
              "      <td>0.240680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>0.169700</td>\n",
              "      <td>0.241585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1660</td>\n",
              "      <td>0.240000</td>\n",
              "      <td>0.215044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1670</td>\n",
              "      <td>0.001700</td>\n",
              "      <td>0.207481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1680</td>\n",
              "      <td>0.006800</td>\n",
              "      <td>0.210202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1690</td>\n",
              "      <td>0.159800</td>\n",
              "      <td>0.224185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.011100</td>\n",
              "      <td>0.223920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1710</td>\n",
              "      <td>0.179600</td>\n",
              "      <td>0.224591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1720</td>\n",
              "      <td>0.081600</td>\n",
              "      <td>0.223599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1730</td>\n",
              "      <td>0.333600</td>\n",
              "      <td>0.227590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1740</td>\n",
              "      <td>0.411800</td>\n",
              "      <td>0.231378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>0.225500</td>\n",
              "      <td>0.218358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1760</td>\n",
              "      <td>0.107900</td>\n",
              "      <td>0.286194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1770</td>\n",
              "      <td>0.266200</td>\n",
              "      <td>0.253226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1780</td>\n",
              "      <td>0.002900</td>\n",
              "      <td>0.218120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1790</td>\n",
              "      <td>0.009900</td>\n",
              "      <td>0.227660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.421000</td>\n",
              "      <td>0.233676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1810</td>\n",
              "      <td>0.135000</td>\n",
              "      <td>0.234488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1820</td>\n",
              "      <td>0.052000</td>\n",
              "      <td>0.278159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1830</td>\n",
              "      <td>0.001600</td>\n",
              "      <td>0.323608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1840</td>\n",
              "      <td>0.186300</td>\n",
              "      <td>0.303807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1850</td>\n",
              "      <td>0.067500</td>\n",
              "      <td>0.279502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1860</td>\n",
              "      <td>0.162200</td>\n",
              "      <td>0.262836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1870</td>\n",
              "      <td>0.013700</td>\n",
              "      <td>0.253761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1880</td>\n",
              "      <td>0.014300</td>\n",
              "      <td>0.258873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1890</td>\n",
              "      <td>0.044500</td>\n",
              "      <td>0.263668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.001200</td>\n",
              "      <td>0.281960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1910</td>\n",
              "      <td>0.001200</td>\n",
              "      <td>0.285083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1920</td>\n",
              "      <td>0.006400</td>\n",
              "      <td>0.274471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1930</td>\n",
              "      <td>0.001700</td>\n",
              "      <td>0.260458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1940</td>\n",
              "      <td>0.143400</td>\n",
              "      <td>0.258259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1950</td>\n",
              "      <td>0.112400</td>\n",
              "      <td>0.259881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1960</td>\n",
              "      <td>0.012800</td>\n",
              "      <td>0.308382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1970</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.343138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1980</td>\n",
              "      <td>0.005000</td>\n",
              "      <td>0.343841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1990</td>\n",
              "      <td>0.004300</td>\n",
              "      <td>0.342064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.001100</td>\n",
              "      <td>0.340282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2010</td>\n",
              "      <td>0.059300</td>\n",
              "      <td>0.332293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2020</td>\n",
              "      <td>0.297900</td>\n",
              "      <td>0.311540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2030</td>\n",
              "      <td>0.001300</td>\n",
              "      <td>0.308806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2040</td>\n",
              "      <td>0.006200</td>\n",
              "      <td>0.320302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2050</td>\n",
              "      <td>0.000900</td>\n",
              "      <td>0.319243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2060</td>\n",
              "      <td>0.000900</td>\n",
              "      <td>0.319157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2070</td>\n",
              "      <td>0.078500</td>\n",
              "      <td>0.316800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2080</td>\n",
              "      <td>0.004300</td>\n",
              "      <td>0.316846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2090</td>\n",
              "      <td>0.001600</td>\n",
              "      <td>0.320840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.080200</td>\n",
              "      <td>0.324486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2110</td>\n",
              "      <td>0.165800</td>\n",
              "      <td>0.323123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2120</td>\n",
              "      <td>0.128300</td>\n",
              "      <td>0.312851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2130</td>\n",
              "      <td>0.001400</td>\n",
              "      <td>0.304647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2140</td>\n",
              "      <td>0.180200</td>\n",
              "      <td>0.277945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2150</td>\n",
              "      <td>0.155800</td>\n",
              "      <td>0.281176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2160</td>\n",
              "      <td>0.370700</td>\n",
              "      <td>0.305316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2170</td>\n",
              "      <td>0.155300</td>\n",
              "      <td>0.316625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2180</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>0.314112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2190</td>\n",
              "      <td>0.367600</td>\n",
              "      <td>0.313871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.119900</td>\n",
              "      <td>0.298670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2210</td>\n",
              "      <td>0.130200</td>\n",
              "      <td>0.287634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2220</td>\n",
              "      <td>0.105300</td>\n",
              "      <td>0.287726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2230</td>\n",
              "      <td>0.057300</td>\n",
              "      <td>0.292719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2240</td>\n",
              "      <td>0.127900</td>\n",
              "      <td>0.319959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2250</td>\n",
              "      <td>0.035500</td>\n",
              "      <td>0.331128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2260</td>\n",
              "      <td>0.401600</td>\n",
              "      <td>0.299063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2270</td>\n",
              "      <td>0.053600</td>\n",
              "      <td>0.293206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2280</td>\n",
              "      <td>0.000700</td>\n",
              "      <td>0.286235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2290</td>\n",
              "      <td>0.001800</td>\n",
              "      <td>0.287231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.038200</td>\n",
              "      <td>0.288048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2310</td>\n",
              "      <td>0.131400</td>\n",
              "      <td>0.287641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2320</td>\n",
              "      <td>0.190000</td>\n",
              "      <td>0.295760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2330</td>\n",
              "      <td>0.002500</td>\n",
              "      <td>0.291927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2340</td>\n",
              "      <td>0.176900</td>\n",
              "      <td>0.288077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2350</td>\n",
              "      <td>0.198400</td>\n",
              "      <td>0.281100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2360</td>\n",
              "      <td>0.175600</td>\n",
              "      <td>0.279049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2370</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>0.277451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2380</td>\n",
              "      <td>0.143100</td>\n",
              "      <td>0.280191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2390</td>\n",
              "      <td>0.071400</td>\n",
              "      <td>0.278575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.117800</td>\n",
              "      <td>0.265004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2410</td>\n",
              "      <td>0.181400</td>\n",
              "      <td>0.259131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2420</td>\n",
              "      <td>0.003000</td>\n",
              "      <td>0.262184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2430</td>\n",
              "      <td>0.105200</td>\n",
              "      <td>0.262203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2440</td>\n",
              "      <td>0.046100</td>\n",
              "      <td>0.258349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2450</td>\n",
              "      <td>0.175700</td>\n",
              "      <td>0.255901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2460</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>0.250195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2470</td>\n",
              "      <td>0.543300</td>\n",
              "      <td>0.251571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2480</td>\n",
              "      <td>0.007700</td>\n",
              "      <td>0.257443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2490</td>\n",
              "      <td>0.003300</td>\n",
              "      <td>0.266181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.192800</td>\n",
              "      <td>0.265474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2510</td>\n",
              "      <td>0.146400</td>\n",
              "      <td>0.261480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2520</td>\n",
              "      <td>0.288700</td>\n",
              "      <td>0.259938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2530</td>\n",
              "      <td>0.224600</td>\n",
              "      <td>0.257772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2540</td>\n",
              "      <td>0.000900</td>\n",
              "      <td>0.254882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2550</td>\n",
              "      <td>0.165100</td>\n",
              "      <td>0.255513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2560</td>\n",
              "      <td>0.001400</td>\n",
              "      <td>0.258492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2570</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.258137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2580</td>\n",
              "      <td>0.294600</td>\n",
              "      <td>0.257480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2590</td>\n",
              "      <td>0.058200</td>\n",
              "      <td>0.258707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.105900</td>\n",
              "      <td>0.259908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2610</td>\n",
              "      <td>0.000900</td>\n",
              "      <td>0.260388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2620</td>\n",
              "      <td>0.165000</td>\n",
              "      <td>0.261274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2630</td>\n",
              "      <td>0.001600</td>\n",
              "      <td>0.262124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2640</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>0.262404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2650</td>\n",
              "      <td>0.002200</td>\n",
              "      <td>0.262704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2660</td>\n",
              "      <td>0.075700</td>\n",
              "      <td>0.263048</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2664, training_loss=0.20117756203040704, metrics={'train_runtime': 747.5735, 'train_samples_per_second': 14.246, 'train_steps_per_second': 3.564, 'total_flos': 1205887849345368.0, 'train_loss': 0.20117756203040704, 'epoch': 3.0})"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHbeV9GyK1-q",
        "outputId": "9b20c788-0ff5-456a-e39f-227fc182be13"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('./phobert-sentiment/tokenizer_config.json',\n",
              " './phobert-sentiment/special_tokens_map.json',\n",
              " './phobert-sentiment/vocab.txt',\n",
              " './phobert-sentiment/bpe.codes',\n",
              " './phobert-sentiment/added_tokens.json')"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.save_model()\n",
        "tokenizer.save_pretrained(args.output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "IxXLnr64TEuR"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/phobert-sentiment\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"/content/phobert-sentiment\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZJhQbZjTWok",
        "outputId": "baf50962-6a6f-4520-f4ea-c08cdd1e5424"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'text': 'sản phẩm tốt', 'prediction': 'Tích cực', 'confidence': 0.9994471669197083, 'probabilities': {'Tiêu cực': 0.0002, 'Trung lập': 0.0004, 'Tích cực': 0.9994}}\n",
            "{'text': 'Sản phẩm tệ quá, không bao giờ mua lại', 'prediction': 'Tiêu cực', 'confidence': 0.9993475079536438, 'probabilities': {'Tiêu cực': 0.9993, 'Trung lập': 0.0005, 'Tích cực': 0.0002}}\n",
            "{'text': 'Cũng bình thường thôi, không có gì đặc biệt', 'prediction': 'Tích cực', 'confidence': 0.4864797592163086, 'probabilities': {'Tiêu cực': 0.1148, 'Trung lập': 0.3987, 'Tích cực': 0.4865}}\n"
          ]
        }
      ],
      "source": [
        "def predict(text: str):\n",
        "    # Tokenize\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",      # trả về tensor pytorch\n",
        "        truncation=True,\n",
        "        max_length=256,\n",
        "        padding=True              # thêm padding để tránh lỗi shape\n",
        "    )\n",
        "\n",
        "    # Di chuyển inputs sang cùng device với model (GPU/CPU)\n",
        "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "\n",
        "    # Dự đoán\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "    # Tính xác suất\n",
        "    probabilities = torch.softmax(logits, dim=-1).squeeze().cpu().numpy()\n",
        "\n",
        "    # Lấy nhãn dự đoán\n",
        "    predicted_id = int(probabilities.argmax())\n",
        "    label_map = {0: \"Tiêu cực\", 1: \"Trung lập\", 2: \"Tích cực\"}\n",
        "    predicted_label = label_map[predicted_id]\n",
        "\n",
        "    # Trả về kết quả đẹp\n",
        "    return {\n",
        "        \"text\": text,\n",
        "        \"prediction\": predicted_label,\n",
        "        \"confidence\": float(probabilities.max()),\n",
        "        \"probabilities\": {\n",
        "            \"Tiêu cực\": round(float(probabilities[0]), 4),\n",
        "            \"Trung lập\": round(float(probabilities[1]), 4),\n",
        "            \"Tích cực\": round(float(probabilities[2]), 4)\n",
        "        }\n",
        "    }\n",
        "\n",
        "# Test nhanh\n",
        "print(predict(\"sản phẩm tốt\"))\n",
        "print(predict(\"Sản phẩm tệ quá, không bao giờ mua lại\"))\n",
        "print(predict(\"Cũng bình thường thôi, không có gì đặc biệt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6f043325bafb4963a9d6f903754294bf",
            "bbecf289b0ce446092f5ac5c76a390b3",
            "92d4ffbe8a944196936ec70249a9da11",
            "79291e0703b74683aab7025a42c846d4",
            "80d971a97494400d80a12b14f1296cbd",
            "59910d3ac6534b789d45fd6b886d78fc",
            "4b60796e2fac49cb9f5d91a8e962591b",
            "6162856b0c4f411996b4b34fa8c3d7ec",
            "0b96e5f99730456f8cdccdcc4b148111",
            "0985ef028e9e44609f71086c1b9c0ccb",
            "2e16faed283041fca49f42bfbb4bb395"
          ]
        },
        "id": "-HEHQ5g7Vhvd",
        "outputId": "4deb3190-d9ce-40de-e8f7-1a7a38032c38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "CÁCH 1: Đánh giá truyền thống trên 300 mẫu test...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7/7 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "CÁCH 2: Đánh giá bằng Gemini (LLM Judge)...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f043325bafb4963a9d6f903754294bf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "LLM Judge:   0%|          | 0/300 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 528.84ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.65ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 529.06ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 529.06ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 506.21ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.89ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 528.69ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 528.94ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 830.63ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 705.05ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 504.63ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.54ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.70ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 556.51ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.55ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 604.29ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 478.27ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 528.74ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 530.74ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.83ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 528.94ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 504.27ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 504.18ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 578.95ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 729.70ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.78ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 554.14ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.79ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.43ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 553.96ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 528.79ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 783.25ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.53ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 554.36ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 504.04ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 553.97ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.99ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 529.02ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.65ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.92ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 555.98ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.90ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 504.14ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.57ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 478.55ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.71ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 528.69ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 528.93ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 529.65ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 504.25ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 529.72ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 504.63ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.79ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 478.70ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 529.27ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.79ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 528.92ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 478.76ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 529.17ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 505.52ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 478.73ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 529.09ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.52ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 528.76ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 931.86ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.92ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 529.03ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 554.63ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 504.62ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 604.39ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 478.52ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 529.00ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 504.31ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 478.54ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 478.48ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 554.02ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 530.00ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 504.60ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 478.87ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 528.65ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.92ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.59ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 478.61ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.71ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.84ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 478.49ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 655.62ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.95ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 554.15ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 529.09ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 504.45ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.72ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 505.04ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 529.26ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 478.95ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 479.17ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 529.20ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 478.83ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.67ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 528.86ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 478.73ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 478.62ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.59ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 504.25ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 504.08ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 553.85ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.61ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 529.23ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 528.68ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.51ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 529.42ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.87ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 528.78ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 554.45ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 528.75ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.52ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 528.91ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 554.00ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 528.69ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 479.35ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.63ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 528.81ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 479.70ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.94ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 529.90ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 478.88ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 504.06ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 478.63ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 479.10ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 478.66ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 528.97ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 479.20ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 481.21ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 578.91ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 931.40ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 504.14ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.51ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 553.89ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.60ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.57ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 604.52ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 504.03ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.80ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.82ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 478.27ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 528.70ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 529.29ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.76ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 478.55ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.80ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 508.88ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 478.40ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.98ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 529.31ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 528.81ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.74ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 604.61ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.63ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 478.41ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 554.82ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 478.83ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 554.41ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 504.35ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 478.60ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 529.84ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 504.65ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 529.21ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 528.80ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 506.17ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 478.57ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.62ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.56ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 528.80ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.95ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.64ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.61ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.63ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 479.12ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 530.57ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 478.90ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.86ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.89ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 478.48ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 478.54ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 528.96ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 528.92ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.94ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 480.16ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 528.64ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.60ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 528.84ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.65ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.63ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 528.71ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 529.18ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.92ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 531.49ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.92ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 529.41ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.77ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 528.80ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.55ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.63ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.67ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.73ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 505.17ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.68ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 478.75ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.57ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.65ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 478.42ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.62ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 806.24ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 554.41ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 504.08ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 528.69ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.77ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 654.47ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 654.57ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 528.74ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 504.36ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.66ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.63ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 505.55ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 780.51ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 654.78ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.81ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 530.56ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 478.93ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.82ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 805.38ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 504.35ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 504.88ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 478.37ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.79ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.89ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.70ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.79ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.85ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 528.95ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 504.48ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 479.03ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 479.37ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.78ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 505.06ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 554.25ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.60ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 478.48ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 528.72ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 478.83ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 479.35ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 478.63ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.72ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 478.72ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.65ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.64ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 478.67ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.51ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.69ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 505.39ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 480.60ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.59ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.57ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 478.46ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.75ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.55ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.71ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.56ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.68ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 555.08ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 504.97ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.55ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 504.52ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.55ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.50ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 478.77ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 554.26ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 478.33ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 504.96ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.84ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 479.23ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.78ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 504.66ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 478.92ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.98ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.79ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 478.71ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 480.13ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 505.62ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 528.82ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 504.81ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 529.33ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.71ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 529.09ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 554.05ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 528.88ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 529.11ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 479.90ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 503.62ms\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "KẾT QUẢ ĐÁNH GIÁ TRÊN minhtoan/vietnamese-comment-sentiment (300 mẫu test)\n",
            "================================================================================\n",
            "CÁCH 1 - TRUYỀN THỐNG (Trainer)\n",
            "   Accuracy    : 0.9392\n",
            "   F1-macro    : 0.9488\n",
            "--------------------------------------------------------------------------------\n",
            "CÁCH 2 - LLM-as-a-Judge\n",
            "   LLM Judge Score : 0.4983 (càng gần 1.0 càng tốt)\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "import time\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=TrainingArguments(output_dir=\"./temp\", per_device_eval_batch_size=64, report_to=[]),\n",
        "    eval_dataset=eval_dataset,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=lambda p: {\n",
        "        \"accuracy\": accuracy_score(p.label_ids, np.argmax(p.predictions, axis=1)),\n",
        "        \"f1_macro\": f1_score(p.label_ids, np.argmax(p.predictions, axis=1), average='macro'),\n",
        "    }\n",
        ")\n",
        "\n",
        "print(\"\\nCÁCH 1: Đánh giá truyền thống trên 300 mẫu test...\")\n",
        "result1 = trainer.evaluate()\n",
        "\n",
        "import google.generativeai as genai\n",
        "genai.configure(api_key=\"\")\n",
        "\n",
        "gemini = genai.GenerativeModel('gemini-2.5-flash')\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_sentiment(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=256).to(model.device)\n",
        "    logits = model(**inputs).logits\n",
        "    pred = torch.argmax(logits, dim=-1).item()\n",
        "    return { 0: \"tiêu cực\", 1: \"trung lập\", 2: \"tích cực\" }[pred]\n",
        "\n",
        "def llm_judge_gemini(text, true_str, pred_str):\n",
        "    prompt = f\"\"\"Chỉ trả về đúng 1 số: 1.0 nếu đúng hoàn toàn, 0.5 nếu gần đúng, 0.0 nếu sai.\n",
        "\n",
        "Bình luận: \"{text}\"\n",
        "Cảm xúc thực tế: {true_str}\n",
        "Mô hình dự đoán: {pred_str}\n",
        "\n",
        "Điểm (1.0 / 0.5 / 0.0):\"\"\"\n",
        "    try:\n",
        "        resp = gemini.generate_content(prompt, generation_config={\"temperature\": 0.0})\n",
        "        return float(resp.text.strip())\n",
        "    except:\n",
        "        return 0.5\n",
        "\n",
        "print(\"\\nCÁCH 2: Đánh giá bằng Gemini (LLM Judge)...\")\n",
        "ds_test = ds_clean.select(range(300))\n",
        "llm_scores = []\n",
        "exact = 0\n",
        "for i in tqdm(range(len(ds_test)), desc=\"LLM Judge\"):\n",
        "    ex = ds_test[i]\n",
        "    true_str = \"tích cực\" if ex[\"Sentiment\"] == 1 else \"tiêu cực\"\n",
        "    pred_str = predict_sentiment(ex[\"Content\"])\n",
        "\n",
        "    score = llm_judge_gemini(ex[\"Content\"], true_str, pred_str)\n",
        "    llm_scores.append(score)\n",
        "    if score == 1.0:\n",
        "        exact += 1\n",
        "    time.sleep(0.7)\n",
        "\n",
        "llm_score = np.mean(llm_scores)\n",
        "llm_acc = exact / len(ds_test)\n",
        "\n",
        "# ==================== IN KẾT QUẢ CUỐI CÙNG ====================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"KẾT QUẢ ĐÁNH GIÁ TRÊN minhtoan/vietnamese-comment-sentiment (300 mẫu test)\")\n",
        "print(\"=\"*80)\n",
        "print(f\"CÁCH 1 - TRUYỀN THỐNG (Trainer)\")\n",
        "print(f\"   Accuracy    : {result1['eval_accuracy']:.4f}\")\n",
        "print(f\"   F1-macro    : {result1['eval_f1_macro']:.4f}\")\n",
        "print(\"-\"*80)\n",
        "print(f\"CÁCH 2 - LLM-as-a-Judge\")\n",
        "print(f\"   LLM Judge Score : {llm_score:.4f} (càng gần 1.0 càng tốt)\")\n",
        "print(\"=\"*80)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0985ef028e9e44609f71086c1b9c0ccb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b96e5f99730456f8cdccdcc4b148111": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0ce3d62668db4b6c8bd3a641075c5032": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ae2b6fcbcc94b28bf62e70baf71a455": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e16faed283041fca49f42bfbb4bb395": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3752a8d0a0814555b5ca7161efd27669": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b60796e2fac49cb9f5d91a8e962591b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5590d6b466ab42c4bb8d68d26a41cfeb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59910d3ac6534b789d45fd6b886d78fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6162856b0c4f411996b4b34fa8c3d7ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cf624e84072462bb4f4381900b88202": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ef1a8626c4c349c0bc9963332a51a9b8",
              "IPY_MODEL_be5e9232228948edb3776bbd7022b9a0",
              "IPY_MODEL_e8edb05ccb4c4377a57b0b12c4856a1f"
            ],
            "layout": "IPY_MODEL_5590d6b466ab42c4bb8d68d26a41cfeb"
          }
        },
        "6f043325bafb4963a9d6f903754294bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bbecf289b0ce446092f5ac5c76a390b3",
              "IPY_MODEL_92d4ffbe8a944196936ec70249a9da11",
              "IPY_MODEL_79291e0703b74683aab7025a42c846d4"
            ],
            "layout": "IPY_MODEL_80d971a97494400d80a12b14f1296cbd"
          }
        },
        "79291e0703b74683aab7025a42c846d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0985ef028e9e44609f71086c1b9c0ccb",
            "placeholder": "​",
            "style": "IPY_MODEL_2e16faed283041fca49f42bfbb4bb395",
            "value": " 300/300 [06:17&lt;00:00,  1.24s/it]"
          }
        },
        "80d971a97494400d80a12b14f1296cbd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88a7d13424d6473dab2283d525afe6bc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91790be979c9448dabb7330b0babe293": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "92d4ffbe8a944196936ec70249a9da11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6162856b0c4f411996b4b34fa8c3d7ec",
            "max": 300,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b96e5f99730456f8cdccdcc4b148111",
            "value": 300
          }
        },
        "bbecf289b0ce446092f5ac5c76a390b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59910d3ac6534b789d45fd6b886d78fc",
            "placeholder": "​",
            "style": "IPY_MODEL_4b60796e2fac49cb9f5d91a8e962591b",
            "value": "LLM Judge: 100%"
          }
        },
        "be5e9232228948edb3776bbd7022b9a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c93db8cb964646c8a0887891239a31a5",
            "max": 3945,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91790be979c9448dabb7330b0babe293",
            "value": 3945
          }
        },
        "c93db8cb964646c8a0887891239a31a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8edb05ccb4c4377a57b0b12c4856a1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88a7d13424d6473dab2283d525afe6bc",
            "placeholder": "​",
            "style": "IPY_MODEL_1ae2b6fcbcc94b28bf62e70baf71a455",
            "value": " 3945/3945 [00:07&lt;00:00, 505.04 examples/s]"
          }
        },
        "ef1a8626c4c349c0bc9963332a51a9b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ce3d62668db4b6c8bd3a641075c5032",
            "placeholder": "​",
            "style": "IPY_MODEL_3752a8d0a0814555b5ca7161efd27669",
            "value": "Map: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
